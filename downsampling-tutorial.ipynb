{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Introducing and Loading the Dataset -- Esther"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing and importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /opt/homebrew/lib/python3.11/site-packages (from scipy) (1.24.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (1.24.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /opt/homebrew/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (1.24.2)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (2.2.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (3.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install seaborn\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the dataset from a csv\n",
    "csv = pd.read_csv('data/creditcard.csv')\n",
    "\n",
    "# Convert the data to a pandas dataframe\n",
    "cc_data = pd.DataFrame(csv)\n",
    "\n",
    "# Get the shape of the dataframe: (rows, columns)\n",
    "cc_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205910</th>\n",
       "      <td>135967.0</td>\n",
       "      <td>0.062690</td>\n",
       "      <td>0.678567</td>\n",
       "      <td>-1.468860</td>\n",
       "      <td>-1.560020</td>\n",
       "      <td>3.194188</td>\n",
       "      <td>3.264803</td>\n",
       "      <td>0.435747</td>\n",
       "      <td>0.870444</td>\n",
       "      <td>-0.368149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272509</td>\n",
       "      <td>-0.850037</td>\n",
       "      <td>0.071537</td>\n",
       "      <td>0.599335</td>\n",
       "      <td>-0.514333</td>\n",
       "      <td>0.148846</td>\n",
       "      <td>0.049529</td>\n",
       "      <td>0.074597</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201611</th>\n",
       "      <td>133964.0</td>\n",
       "      <td>0.158362</td>\n",
       "      <td>1.225332</td>\n",
       "      <td>0.869701</td>\n",
       "      <td>2.458392</td>\n",
       "      <td>1.305696</td>\n",
       "      <td>0.438074</td>\n",
       "      <td>1.042112</td>\n",
       "      <td>-0.063737</td>\n",
       "      <td>-1.280418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.497356</td>\n",
       "      <td>-1.521247</td>\n",
       "      <td>0.159402</td>\n",
       "      <td>-1.246548</td>\n",
       "      <td>-0.857361</td>\n",
       "      <td>-0.668322</td>\n",
       "      <td>-0.122106</td>\n",
       "      <td>-0.171481</td>\n",
       "      <td>7.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118220</th>\n",
       "      <td>74998.0</td>\n",
       "      <td>0.858278</td>\n",
       "      <td>-0.432435</td>\n",
       "      <td>0.349065</td>\n",
       "      <td>0.572747</td>\n",
       "      <td>0.217796</td>\n",
       "      <td>1.664819</td>\n",
       "      <td>-0.375621</td>\n",
       "      <td>0.602209</td>\n",
       "      <td>0.211650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018132</td>\n",
       "      <td>0.066197</td>\n",
       "      <td>0.064401</td>\n",
       "      <td>-0.988854</td>\n",
       "      <td>0.074345</td>\n",
       "      <td>0.373416</td>\n",
       "      <td>0.029815</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>81.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199181</th>\n",
       "      <td>132844.0</td>\n",
       "      <td>0.037726</td>\n",
       "      <td>0.885038</td>\n",
       "      <td>0.297772</td>\n",
       "      <td>-0.596567</td>\n",
       "      <td>0.461205</td>\n",
       "      <td>-1.028412</td>\n",
       "      <td>1.026881</td>\n",
       "      <td>-0.201617</td>\n",
       "      <td>-0.097803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250702</td>\n",
       "      <td>-0.519799</td>\n",
       "      <td>0.073256</td>\n",
       "      <td>-0.010947</td>\n",
       "      <td>-0.492770</td>\n",
       "      <td>0.142256</td>\n",
       "      <td>0.252461</td>\n",
       "      <td>0.097542</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238158</th>\n",
       "      <td>149554.0</td>\n",
       "      <td>-4.982520</td>\n",
       "      <td>-7.003254</td>\n",
       "      <td>-0.933225</td>\n",
       "      <td>2.629323</td>\n",
       "      <td>4.375531</td>\n",
       "      <td>-2.457873</td>\n",
       "      <td>-3.098914</td>\n",
       "      <td>1.042842</td>\n",
       "      <td>0.276444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994589</td>\n",
       "      <td>0.061863</td>\n",
       "      <td>0.742641</td>\n",
       "      <td>-1.470329</td>\n",
       "      <td>-2.294274</td>\n",
       "      <td>-1.038241</td>\n",
       "      <td>0.404635</td>\n",
       "      <td>-0.741786</td>\n",
       "      <td>205.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "205910  135967.0  0.062690  0.678567 -1.468860 -1.560020  3.194188  3.264803   \n",
       "201611  133964.0  0.158362  1.225332  0.869701  2.458392  1.305696  0.438074   \n",
       "118220   74998.0  0.858278 -0.432435  0.349065  0.572747  0.217796  1.664819   \n",
       "199181  132844.0  0.037726  0.885038  0.297772 -0.596567  0.461205 -1.028412   \n",
       "238158  149554.0 -4.982520 -7.003254 -0.933225  2.629323  4.375531 -2.457873   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "205910  0.435747  0.870444 -0.368149  ... -0.272509 -0.850037  0.071537   \n",
       "201611  1.042112 -0.063737 -1.280418  ... -0.497356 -1.521247  0.159402   \n",
       "118220 -0.375621  0.602209  0.211650  ... -0.018132  0.066197  0.064401   \n",
       "199181  1.026881 -0.201617 -0.097803  ... -0.250702 -0.519799  0.073256   \n",
       "238158 -3.098914  1.042842  0.276444  ...  0.994589  0.061863  0.742641   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "205910  0.599335 -0.514333  0.148846  0.049529  0.074597    4.49      0  \n",
       "201611 -1.246548 -0.857361 -0.668322 -0.122106 -0.171481    7.58      0  \n",
       "118220 -0.988854  0.074345  0.373416  0.029815  0.000391   81.34      0  \n",
       "199181 -0.010947 -0.492770  0.142256  0.252461  0.097542    3.96      0  \n",
       "238158 -1.470329 -2.294274 -1.038241  0.404635 -0.741786  205.39      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the first five rows of the dataframe:\n",
    "cc_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: Exploratory data analysis -- Ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Fraud: 99.83 % of the dataset\n",
      "Frauds: 0.17 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "#recoding dataset \n",
    "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='Class', palette=colors)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: Data Cleaning and Initializing The Model with sklearn (no undersampling) -- MILLER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_no_dup['text'], \n",
    "                                                    df_no_dup['target'],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation and data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(text, method, rm_stop):\n",
    "    text = re.sub(r\"\\n\",\"\",text)   #remove line breaks\n",
    "    text = text.lower() #convert to lowercase \n",
    "    text = re.sub(r\"\\d+\",\"\",text)   #remove digits and currencies \n",
    "    text = re.sub(r'[\\$\\d+\\d+\\$]', \"\", text)      \n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)   #remove dates \n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)   #remove non-ascii\n",
    "    text = re.sub(r'[^\\w\\s]','',text)   #remove punctuation\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)   #remove hyperlinks\n",
    "    \n",
    "    #remove stop words \n",
    "    if rm_stop == True:\n",
    "        filtered_tokens = [word for word in word_tokenize(text) if not word in set(stopwords.words('english'))]\n",
    "        text = \" \".join(filtered_tokens)\n",
    "        \n",
    "    #lemmatization: typically preferred over stemming\n",
    "    if method == 'L':\n",
    "        lemmer = WordNetLemmatizer()\n",
    "        lemm_tokens = [lemmer.lemmatize(word) for word in word_tokenize(text)]\n",
    "        return \" \".join(lemm_tokens)\n",
    "    \n",
    "    #stemming \n",
    "    if method == 'S':\n",
    "        porter = PorterStemmer()\n",
    "        stem_tokens = [porter.stem(word) for word in word_tokenize(text)]\n",
    "        return \" \".join(stem_tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessed data: Lemm + stopword removal \n",
    "preprocessed_text_1 = [text_clean(text, 'L', True) for text in X_train]\n",
    "#preprocessed_text_1[0:10]\n",
    "\n",
    "#preprocessed data: Lemm + no stopword removal \n",
    "preprocessed_text_2 = [text_clean(text, 'L', False) for text in X_train]\n",
    "#preprocessed_text_2[0:10]\n",
    "\n",
    "#preprocessed data: Stem + stopword removal \n",
    "preprocessed_text_3 = [text_clean(text, 'S', True) for text in X_train]\n",
    "#preprocessed_text_3[0:10]\n",
    "\n",
    "#preprocessed data: Stem + no stopword removal \n",
    "preprocessed_text_4 = [text_clean(text, 'S', False) for text in X_train]\n",
    "#preprocessed_text_4[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WE'RE USING RANDOM FORESTS AS OUR CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_model_data_w_count_vectorizer(preprocessed_text, Y_train,  X_test, Y_test):\n",
    "    #vectorize dataset \n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorized_data = vectorizer.fit_transform(preprocessed_text)\n",
    "\n",
    "    #define model\n",
    "    model = MultinomialNB(alpha=0.1)\n",
    "    model.fit(vectorized_data, Y_train)\n",
    "\n",
    "    #evaluate model\n",
    "    predictions = model.predict(vectorizer.transform(X_test))\n",
    "    accuracy = accuracy_score( Y_test, predictions)\n",
    "    balanced_accuracy = balanced_accuracy_score(Y_test, predictions)\n",
    "    precision = precision_score(Y_test, predictions)\n",
    "\n",
    "    print(\"Accuracy:\",round(100*accuracy,2),'%')\n",
    "    print(\"Balanced accuracy:\",round(100*balanced_accuracy,2),'%')\n",
    "    print(\"Precision:\", round(100*precision,2),'%')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_model_data_w_tfidf_vectorizer(preprocessed_text, Y_train,  X_test, Y_test):\n",
    "    #vectorize dataset \n",
    "    tfidf = TfidfVectorizer() \n",
    "    vectorized_data = tfidf.fit_transform(preprocessed_text)\n",
    "\n",
    "    #define model\n",
    "    model = MultinomialNB(alpha=0.1)\n",
    "    model.fit(vectorized_data, Y_train)\n",
    " \n",
    "    #evaluate model\n",
    "    predictions = model.predict(tfidf.transform(X_test))\n",
    "\n",
    "    accuracy = accuracy_score( Y_test, predictions)\n",
    "    balanced_accuracy = balanced_accuracy_score(Y_test, predictions)\n",
    "    precision = precision_score(Y_test, predictions)\n",
    "\n",
    "    print(\"Accuracy:\",round(100*accuracy,2),'%')\n",
    "    print(\"Balanced accuracy:\",round(100*balanced_accuracy,2),'%')\n",
    "    print(\"Precision:\", round(100*precision,2),'%')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemm + stopword removal + CountVectorizer\n",
      "Accuracy: 97.55 %\n",
      "Balanced accuracy: 94.57 %\n",
      "Precision: 90.55 %\n",
      "\n",
      "Lemm + no stopword removal + CountVectorizer\n",
      "Accuracy: 97.42 %\n",
      "Balanced accuracy: 93.86 %\n",
      "Precision: 90.86 %\n",
      "\n",
      "Stem + stopword removal + CountVectorizer\n",
      "Accuracy: 96.91 %\n",
      "Balanced accuracy: 90.6 %\n",
      "Precision: 93.22 %\n",
      "\n",
      "Stem + no stopword removal + CountVectorizer\n",
      "Accuracy: 97.29 %\n",
      "Balanced accuracy: 91.88 %\n",
      "Precision: 93.92 %\n"
     ]
    }
   ],
   "source": [
    "#vectorize, model, and evaluate model using CountVectorizer\n",
    "\n",
    "#Lemm + stopword removal \n",
    "print(\"Lemm + stopword removal + CountVectorizer\") \n",
    "transform_model_data_w_count_vectorizer(preprocessed_text_1, Y_train,  X_test, Y_test)\n",
    "\n",
    "#Lemm + no stopword removal \n",
    "print(\"\\nLemm + no stopword removal + CountVectorizer\") \n",
    "transform_model_data_w_count_vectorizer(preprocessed_text_2, Y_train,  X_test, Y_test)\n",
    "\n",
    "#Stem + stopword removal \n",
    "print(\"\\nStem + stopword removal + CountVectorizer\") \n",
    "transform_model_data_w_count_vectorizer(preprocessed_text_3, Y_train,  X_test, Y_test)\n",
    "\n",
    "#Stem + no stopword removal \n",
    "print(\"\\nStem + no stopword removal + CountVectorizer\") \n",
    "transform_model_data_w_count_vectorizer(preprocessed_text_4, Y_train,  X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemm + stopword removal + TfidfVectorizer\n",
      "Accuracy: 97.36 %\n",
      "Balanced accuracy: 91.92 %\n",
      "Precision: 94.44 %\n",
      "\n",
      "Lemm + no stopword removal + TfidfVectorizer\n",
      "Accuracy: 97.61 %\n",
      "Balanced accuracy: 92.07 %\n",
      "Precision: 96.59 %\n",
      "\n",
      "Stem + stopword removal + TfidfVectorizer\n",
      "Accuracy: 96.07 %\n",
      "Balanced accuracy: 85.46 %\n",
      "Precision: 97.95 %\n",
      "\n",
      "Stem + no stopword removal + TfidfVectorizer\n",
      "Accuracy: 96.45 %\n",
      "Balanced accuracy: 86.53 %\n",
      "Precision: 99.32 %\n"
     ]
    }
   ],
   "source": [
    "#vectorize, model, and evaluate model using TfidfVectorizer\n",
    "\n",
    "#Lemm + stopword removal \n",
    "print(\"Lemm + stopword removal + TfidfVectorizer\") \n",
    "transform_model_data_w_tfidf_vectorizer(preprocessed_text_1, Y_train,  X_test, Y_test)\n",
    "\n",
    "#Lemm + no stopword removal \n",
    "print(\"\\nLemm + no stopword removal + TfidfVectorizer\") \n",
    "transform_model_data_w_tfidf_vectorizer(preprocessed_text_2, Y_train,  X_test, Y_test)\n",
    "\n",
    "#Stem + stopword removal \n",
    "print(\"\\nStem + stopword removal + TfidfVectorizer\") \n",
    "transform_model_data_w_tfidf_vectorizer(preprocessed_text_3, Y_train,  X_test, Y_test)\n",
    "\n",
    "#Stem + no stopword removal \n",
    "print(\"\\nStem + no stopword removal + TfidfVectorizer\") \n",
    "transform_model_data_w_tfidf_vectorizer(preprocessed_text_4, Y_train,  X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.45 %\n",
      "Balanced accuracy: 86.53 %\n",
      "Precision: 99.32 %\n"
     ]
    }
   ],
   "source": [
    "predictions = transform_model_data_w_tfidf_vectorizer(preprocessed_text_4, Y_train,  X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compute the confusion matrix.\n",
    "cm = confusion_matrix(Y_test, predictions)\n",
    "\n",
    " #Plot the confusion matrix.\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4b: Evaluation with Performance Metrics -- Alyssa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: Undersampling Techniques -- Esther (just write the general blurb for this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Downsampling -- Esther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time        V1        V2        V3        V4        V5        V6  \\\n",
       "541    406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "623    472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "4920  4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "6108  6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "6329  7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "541  -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
       "623   0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "4920  0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
       "6108 -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
       "6329  1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
       "\n",
       "           V24       V25       V26       V27       V28  Amount  Class  \n",
       "541   0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "623  -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "4920 -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "6108 -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "6329 -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraud_df = cc_data.loc[cc_data['Class'] == 1]\n",
    "non_fraud_df = cc_data.loc[cc_data['Class'] == 0][:492]\n",
    "display(fraud_df.head())\n",
    "display(non_fraud_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam and Ham Stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "\n",
    "sns.countplot(data=df, x='Class', palette=colors)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 common duplicate texts are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sorry, I'll call later</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I cant pick the phone right now. Pls send a message</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ok...</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Say this slowly.? GOD,I LOVE YOU &amp;amp; I NEED YOU,CLEAN MY HEART WITH YOUR BLOOD.Send this to Ten special people &amp;amp; u c miracle tomorrow, do it,pls,pls do it...</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wen ur lovable bcums angry wid u, dnt take it seriously.. Coz being angry is d most childish n true way of showing deep affection, care n luv!.. kettoda manda... Have nice day da.</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    target\n",
       "text                                                      \n",
       "Sorry, I'll call later                                  30\n",
       "I cant pick the phone right now. Pls send a mes...      12\n",
       "Ok...                                                   10\n",
       "Say this slowly.? GOD,I LOVE YOU &amp; I NEED Y...       4\n",
       "Wen ur lovable bcums angry wid u, dnt take it s...       4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Top 5 common duplicate texts are:')\n",
    "data[data.duplicates == 1].pivot_table(index='text', values='target', aggfunc='count').sort_values(by='target', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in each column:\n",
      "classification    0\n",
      "text              0\n",
      "target            0\n",
      "duplicates        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for missing data\n",
    "print(\"Missing data in each column:\\n\" + str(data.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4825\n",
       "1     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore distribution of dataset \n",
    "\n",
    "# count plot on single categorical variable\n",
    "ax = sns.countplot(x = data['classification'], palette = 'rocket')\n",
    "\n",
    "#add data labels\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "# add plot title\n",
    "plt.title(\"Observations by Classification Type\")\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Distribution of dataset indicates imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all duplicate texts based off of results of EDA\n",
    "df_no_dup = data.drop_duplicates(subset=['text'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore distribution of dataset \n",
    "\n",
    "# count plot on single categorical variable\n",
    "ax = sns.countplot(x = df_no_dup['classification'], palette = 'rocket')\n",
    "\n",
    "#add data labels\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "# add plot title\n",
    "plt.title(\"Observations by Classification Type\")\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Near Miss Undersampling -- Ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/riajain/Desktop/cody/think/downsampling-tutorial.ipynb Cell 38\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/riajain/Desktop/cody/think/downsampling-tutorial.ipynb#Y256sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimblearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39munder_sampling\u001b[39;00m \u001b[39mimport\u001b[39;00m NearMiss\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/riajain/Desktop/cody/think/downsampling-tutorial.ipynb#Y256sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#Splitting the data into features and labels \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/riajain/Desktop/cody/think/downsampling-tutorial.ipynb#Y256sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m X \u001b[39m=\u001b[39m cc_data\u001b[39m.\u001b[39miloc[:,:\u001b[39m30\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "#Splitting the data into features and labels \n",
    "X = cc_data.iloc[:,:30]\n",
    "y = cc_data.iloc[:, 30]\n",
    "\n",
    "near_miss = NearMiss()\n",
    "X_resample, y_resample = near_miss.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before Undersampling, counts of label '1': {}\".format(sum(y == 1)))\n",
    "print(\"Before Undersampling, counts of label '0': {} \\n\".format(sum(y == 0))) \n",
    "  \n",
    "print(\"After Undersampling, counts of label '1': {}\".format(sum(y_resample == 1))) \n",
    "print(\"After Undersampling, counts of label '0': {}\".format(sum(y_resample == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the classifier \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resample, y_resample, test_size=0.2, random_state=45)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "score = model.score(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tomek Link Undersampling -- Miller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
