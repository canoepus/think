{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary packages\n",
    "%pip install pandas\n",
    "%pip install scipy\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install scikit-learn\n",
    "%pip install numpy\n",
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "# For loading, processing, and displaying data\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "# For Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# For evaluating Classifier\n",
    "from sklearn import metrics\n",
    "# For Random Upsampling\n",
    "from sklearn.utils import resample\n",
    "# For SMOTE and Borderline SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset downloaded from: https://archive.ics.uci.edu/dataset/266/seismic+bumps\n",
    "# Load in the arff file\n",
    "arff_file = arff.loadarff('data/seismic-bumps.arff')\n",
    "\n",
    "# Convert to a pandas dataframe\n",
    "data = pd.DataFrame(arff_file[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shape of dataframe: (rows, columns)\n",
    "print(\"Shape of dataframe (rows, columns): \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peek into the dataframe\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn countplot documentation: https://seaborn.pydata.org/generated/seaborn.countplot.html\n",
    "# Create a bar chart to plot counts of each class\n",
    "ax = sns.countplot(x = data['class'], hue=data['class'])\n",
    "\n",
    "# Add plot title\n",
    "plt.title(\"Observations by Classification Type\")\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process/Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only the numerical data columns\n",
    "input_cols = [i for i in range(data.shape[1]) if i not in ([0, 1, 2, 7, 18])]\n",
    "\n",
    "# Split into input, X, and output, Y\n",
    "X = data.iloc[:,input_cols]\n",
    "Y = data.iloc[:,-1].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of each\n",
    "print(\"Shape of X: \", X.shape)\n",
    "print(\"Shape of Y: \", Y.shape)\n",
    "\n",
    "# Peek into each dataframe\n",
    "display(X.head(5))\n",
    "display(Y.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some features of the input data with the majority and minority class labels\n",
    "# Seaborn Scatterplot documentation: https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "ax = sns.scatterplot(data=data, x='genergy', y='gpuls', hue='class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into the train and test set\n",
    "# Scikitlearn train_test_split documentation: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the classifier. Use default values except the random_state, \n",
    "# which sets the seed for the randomness in bootstrapping the data for each decision tree\n",
    "# Sklearn Random Forest documentation: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "baseline_classifier = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# FIt the classifier to the data\n",
    "baseline_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the test set through the model\n",
    "# This function outputs the probability for each class\n",
    "baseline_output = baseline_classifier.predict_proba(X_test)\n",
    "\n",
    "# Peek into a few predicted output probabilities: (probability of class 0, probability of class 1)\n",
    "print(baseline_output[:5])\n",
    "\n",
    "# Grab the predicted probabilities for class 1 (We treat this as the positive, minority class)\n",
    "y_class1_pred_prob = baseline_output[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the False Positive and True Positive rates for later comparison\n",
    "# Sklearn roc_curve documentation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html\n",
    "baseline_fpr, baseline_tpr, _ = metrics.roc_curve(Y_test, y_class1_pred_prob, pos_label=1) # pos_label specifies which class is the positive class\n",
    "\n",
    "# Finding the AUC score for later comparison\n",
    "# Sklearn auc documentation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html\n",
    "baseline_roc_auc = metrics.auc(baseline_fpr, baseline_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the ROC curve\n",
    "# Sklearn RocCurveDisplay documentation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html\n",
    "baseline_display_roc = metrics.RocCurveDisplay.from_predictions(\n",
    "    Y_test,\n",
    "    y_class1_pred_prob, \n",
    "    pos_label=1, # Specify that class 1 is the positive class\n",
    "    name='Baseline Classifier', \n",
    "    plot_chance_level=True # Plots the ROC curve for a random classifier\n",
    ")\n",
    "\n",
    "# Labeling and titling the plot\n",
    "plt.title(\"ROC Curve for Baseline Model\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get precision recall on the test set for later comparison\n",
    "# Sklearn precision_recall_curve: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html\n",
    "baseline_precision, baseline_recall, _ = metrics.precision_recall_curve(Y_test, y_class1_pred_prob)\n",
    "\n",
    "# Getting the AUC for later comparison\n",
    "baseline_pr_auc = metrics.auc(baseline_recall, baseline_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the P-R Curve\n",
    "# Sklearn PrecisionRecallDisplay documentation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.PrecisionRecallDisplay.html\n",
    "baseline_display_pr = metrics.PrecisionRecallDisplay.from_predictions(\n",
    "    Y_test,\n",
    "    y_class1_pred_prob,\n",
    "    pos_label = 1,\n",
    "    name = \"Baseline Classifier\",\n",
    "    plot_chance_level=True # Plots the PR curve of a random classifier\n",
    ")\n",
    "\n",
    "# Labeling the plot\n",
    "plt.title(\"Precision-Recall for Baseline Model\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly upsample the data, then split again\n",
    "# Imblearn Documentation: https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler\n",
    "tmpx, tmpy = RandomOverSampler().fit_resample(X, Y)\n",
    "X_train_randup, _, Y_train_randup, _ = train_test_split(tmpx, tmpy, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of dataset sizes\n",
    "counter = Counter(Y_train)\n",
    "total = counter[0] + counter[1]\n",
    "print('Before using Random Upsampling')\n",
    "print('Number of data points in class 1:  ', counter[0])\n",
    "print('Number of data points in class 2: ', counter[1])\n",
    "print('Class 0: ', round(counter[0] / total * 100, 2), \n",
    "\t\t\t'%, Class 1: ', round(counter[1] / total * 100, 2), '%\\n')\n",
    "\n",
    "counter = Counter(Y_train_randup)\n",
    "total = counter[0] + counter[1]\n",
    "print('After using Random Upsampling')\n",
    "print('Number of data points in class 1:  ', counter[0])\n",
    "print('Number of data points in class 2: ', counter[1])\n",
    "print('Class 0: ', round(counter[0] / total * 100, 2), \n",
    "\t\t\t'%, Class 1: ', round(counter[1] / total * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the new data\n",
    "randup_df = pd.concat([X_train_randup, Y_train_randup], axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "sns.scatterplot(data=randup_df, x='genergy', y='gpuls', hue='class', ax=axes[0])\n",
    "axes[0].set_title('Using Random Upsampling Technique')\n",
    "sns.scatterplot(data=data, x='genergy', y='gpuls', hue='class', ax=axes[1])\n",
    "axes[1].set_title('Original Dataset')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and fitting classifer to Random Upsampled data\n",
    "randup_model = RandomForestClassifier(random_state=0)\n",
    "randup_model.fit(X_train_randup, Y_train_randup)\n",
    "randup_output = randup_model.predict_proba(X_test)\n",
    "y_class1_pred_prob_randup = randup_output[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics: False Positive Rate, True Positive Rate, Precision, and Recall\n",
    "randup_fpr, randup_tpr, _ = metrics.roc_curve(Y_test, y_class1_pred_prob_randup, pos_label=1)\n",
    "randup_roc_auc = metrics.auc(randup_fpr, randup_tpr)\n",
    "randup_precision, randup_recall, _ = metrics.precision_recall_curve(Y_test, y_class1_pred_prob_randup)\n",
    "randup_pr_auc = metrics.auc(randup_recall, randup_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot the ROC Curve\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    Y_test,\n",
    "    y_class1_pred_prob_randup, \n",
    "    pos_label=1,\n",
    "    name='Random Upsampling Classifier', \n",
    "    plot_chance_level=True,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"ROC Curve for Random Upsampling Model\")\n",
    "axes[0].set_xlabel(\"False Positive Rate\")\n",
    "axes[0].set_ylabel(\"True Positive Rate\")\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "metrics.PrecisionRecallDisplay.from_predictions(\n",
    "    Y_test,\n",
    "    y_class1_pred_prob_randup,\n",
    "    pos_label = 1,\n",
    "    name = \"Random Upsampling Classifier\",\n",
    "    plot_chance_level=True,\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Precision-Recall for Random Upsampling Model\")\n",
    "axes[1].set_xlabel(\"Recall\")\n",
    "axes[1].set_ylabel(\"Precision\")\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying SMOTE to the training data\n",
    "# Imblearn SMOTE documentation: https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html\n",
    "tmpx, tmpy = SMOTE().fit_resample(X, Y)\n",
    "X_train_SMOTE, _, Y_train_SMOTE, _ = train_test_split(tmpx, tmpy, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of dataset sizes\n",
    "counter = Counter(Y_train)\n",
    "total = counter[0] + counter[1]\n",
    "print('Before using SMOTE')\n",
    "print('Number of data points in class 1:  ', counter[0])\n",
    "print('Number of data points in class 2: ', counter[1])\n",
    "print('Class 0: ', round(counter[0] / total * 100, 2), '%, Class 1: ', round(counter[1] / total * 100, 2), '%\\n')\n",
    "\n",
    "counter = Counter(Y_train_SMOTE)\n",
    "total = counter[0] + counter[1]\n",
    "print('After Using SMOTE')\n",
    "print('Number of data points in class 1:  ', counter[0])\n",
    "print('Number of data points in class 2: ', counter[1])\n",
    "print('Class 0: ', round(counter[0] / total * 100, 2), '%, Class 1: ', round(counter[1] / total * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the new data\n",
    "SMOTEDf = pd.concat([X_train_SMOTE, Y_train_SMOTE], axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "sns.scatterplot(data=SMOTEDf, x='genergy', y='gpuls', hue='class', ax=axes[0])\n",
    "axes[0].set_title('Using SMOTE technique')\n",
    "sns.scatterplot(data=data, x='genergy', y='gpuls', hue='class', ax=axes[1])\n",
    "axes[1].set_title('Original Dataset')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I feel like we should embedded this code in like a drop down to save space because most of it is repeat stuff\n",
    "# If the user wants to look at it again then sure let them, but at the end we should compare all ROC curves\n",
    "\n",
    "# Building and fitting the classifier to the SMOTE data\n",
    "SMOTE_model = RandomForestClassifier(random_state=0)\n",
    "SMOTE_model.fit(X_train_SMOTE, Y_train_SMOTE)\n",
    "output = SMOTE_model.predict_proba(X_test)\n",
    "y_class1_pred_prob_SMOTE = output[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics: False Positive Rate, True Positive Rate, Precision, and Recall\n",
    "SMOTE_fpr, SMOTE_tpr, _ = metrics.roc_curve(Y_test, y_class1_pred_prob_SMOTE, pos_label=1)\n",
    "SMOTE_roc_auc = metrics.auc(SMOTE_fpr, SMOTE_tpr)\n",
    "SMOTE_precision, SMOTE_recall, _ = metrics.precision_recall_curve(Y_test, y_class1_pred_prob_SMOTE)\n",
    "SMOTE_pr_auc = metrics.auc(SMOTE_recall, SMOTE_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot the ROC Curve\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    Y_test,\n",
    "    y_class1_pred_prob_SMOTE, \n",
    "    pos_label=1,\n",
    "    name='SMOTE Classifier', \n",
    "    plot_chance_level=True,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"ROC Curve for SMOTE Upsampling Model\")\n",
    "axes[0].set_xlabel(\"False Positive Rate\")\n",
    "axes[0].set_ylabel(\"True Positive Rate\")\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "metrics.PrecisionRecallDisplay.from_predictions(\n",
    "    Y_test,\n",
    "    y_class1_pred_prob_SMOTE,\n",
    "    pos_label = 1,\n",
    "    name = \"SMOTE Classifier\",\n",
    "    plot_chance_level=True,\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Precision-Recall for SMOTE Upsampling Model\")\n",
    "axes[1].set_xlabel(\"Recall\")\n",
    "axes[1].set_ylabel(\"Precision\")\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borderline SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying SMOTE to the training data\n",
    "# Imblearn SMOTE documentation: https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.BorderlineSMOTE.html\n",
    "tmpx, tmpy = BorderlineSMOTE().fit_resample(X, Y)\n",
    "X_train_BordSMOTE, _, Y_train_BordSMOTE, _ = train_test_split(tmpx, tmpy, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of dataset sizes\n",
    "counter = Counter(Y_train)\n",
    "total = counter[0] + counter[1]\n",
    "print('Before using Borderline SMOTE')\n",
    "print('Number of data points in class 1:  ', counter[0])\n",
    "print('Number of data points in class 2: ', counter[1])\n",
    "print('Class 0: ', round(counter[0] / total * 100, 2), '%, Class 1: ', round(counter[1] / total * 100, 2), '%\\n')\n",
    "\n",
    "counter = Counter(Y_train_BordSMOTE)\n",
    "total = counter[0] + counter[1]\n",
    "print('After Using Borderline SMOTE')\n",
    "print('Number of data points in class 1:  ', counter[0])\n",
    "print('Number of data points in class 2: ', counter[1])\n",
    "print('Class 0: ', round(counter[0] / total * 100, 2), '%, Class 1: ', round(counter[1] / total * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the new data\n",
    "BordSMOTEDf = pd.concat([X_train_BordSMOTE, Y_train_BordSMOTE], axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "sns.scatterplot(data=BordSMOTEDf, x='genergy', y='gpuls', hue='class', ax=axes[0])\n",
    "axes[0].set_title('Using Borderline SMOTE technique')\n",
    "sns.scatterplot(data=data, x='genergy', y='gpuls', hue='class', ax=axes[1])\n",
    "axes[1].set_title('Original Dataset')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I feel like we should embedded this code in like a drop down to save space because most of it is repeat stuff\n",
    "# If the user wants to look at it again then sure let them, but at the end we should compare all ROC curves\n",
    "\n",
    "# Building and fitting the classifier to the SMOTE data\n",
    "BordSMOTE_model = RandomForestClassifier(random_state=0)\n",
    "BordSMOTE_model.fit(X_train_BordSMOTE, Y_train_BordSMOTE)\n",
    "output = BordSMOTE_model.predict_proba(X_test)\n",
    "y_class1_pred_prob_BordSMOTE = output[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics: False Positive Rate, True Positive Rate, Precision, and Recall\n",
    "BordSMOTE_fpr, BordSMOTE_tpr, _ = metrics.roc_curve(Y_test, y_class1_pred_prob_BordSMOTE, pos_label=1)\n",
    "BordSMOTE_roc_auc = metrics.auc(BordSMOTE_fpr, BordSMOTE_tpr)\n",
    "BordSMOTE_precision, BordSMOTE_recall, _ = metrics.precision_recall_curve(Y_test, y_class1_pred_prob_BordSMOTE)\n",
    "BordSMOTE_pr_auc = metrics.auc(BordSMOTE_recall, BordSMOTE_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot the ROC Curve\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    Y_test,\n",
    "    y_class1_pred_prob_BordSMOTE, \n",
    "    pos_label=1,\n",
    "    name='Borderline SMOTE Classifier', \n",
    "    plot_chance_level=True,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"ROC Curve for Borderline SMOTE Upsampling Model\")\n",
    "axes[0].set_xlabel(\"False Positive Rate\")\n",
    "axes[0].set_ylabel(\"True Positive Rate\")\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "metrics.PrecisionRecallDisplay.from_predictions(\n",
    "    Y_test,\n",
    "    y_class1_pred_prob_BordSMOTE,\n",
    "    pos_label = 1,\n",
    "    name = \"Borderline SMOTE Classifier\",\n",
    "    plot_chance_level=True,\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Precision-Recall for Borderline SMOTE Upsampling Model\")\n",
    "axes[1].set_xlabel(\"Recall\")\n",
    "axes[1].set_ylabel(\"Precision\")\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 grid of plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "# Plot using Borderline SMOTE technique\n",
    "sns.scatterplot(data=BordSMOTEDf, x='genergy', y='gpuls', hue='class', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Using Borderline SMOTE technique')\n",
    "\n",
    "# Plot using SMOTE technique\n",
    "sns.scatterplot(data=SMOTEDf, x='genergy', y='gpuls', hue='class', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Using SMOTE technique')\n",
    "\n",
    "# Plot using Random Upsampled Data\n",
    "sns.scatterplot(data=df_random_upsampled, x='genergy', y='gpuls', hue='class', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Random Upsampled Data')\n",
    "\n",
    "# Plot the original dataset\n",
    "sns.scatterplot(data=data, x='genergy', y='gpuls', hue='class', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Original Dataset')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BordSMOTE_model = RandomForestClassifier(random_state=0)\n",
    "# SMOTE_model = RandomForestClassifier(random_state=0)\n",
    "# classifier_randomly_upsampled = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "print(\"ROC-AUC\\n\" + \"=\" * 20)\n",
    "print(f\"Baseline: {baseline_roc_auc}\\n\\\n",
    "Random Upsampling: {randup_roc_auc}\\n\\\n",
    "SMOTE: {SMOTE_roc_auc}\\n\\\n",
    "Borderline-SMOTE: {BordSMOTE_roc_auc}\")\n",
    "print()\n",
    "print(\"PR-AUC\\n\" + \"=\" * 20)\n",
    "print(f\"Baseline: {baseline_pr_auc}\\n\\\n",
    "Random Upsampling: {randup_pr_auc}\\n\\\n",
    "SMOTE: {SMOTE_pr_auc}\\n\\\n",
    "Borderline-SMOTE: {BordSMOTE_pr_auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
